# Transformer Time Series Forecasting

A deep learning project implementing transformer models for time series forecasting, with support for both point predictions and probabilistic forecasting. The project is designed to work with the M4 competition dataset and includes features for efficient data sampling and GPU acceleration via DirectML.

## Features

- ðŸ¤– Transformer-based architecture with multi-head attention
- ðŸ“Š Support for both point predictions and probabilistic forecasting
- ðŸŽ¯ Multiple loss functions: MSE, Gaussian NLL, sMAPE, and hybrid loss
- ðŸ”„ Efficient data sampling for quick experimentation
- ðŸ’» GPU acceleration with DirectML (supports both NVIDIA and AMD GPUs)
- ðŸ“ˆ Comprehensive visualization tools
- ðŸ§ª Validation and testing pipeline

## Project Structure

```
.
â”œâ”€â”€ api/                # API implementation
â”œâ”€â”€ config/             # Configuration files
â”œâ”€â”€ data/              # Data directory
â”‚   â”œâ”€â”€ raw/           # Raw M4 competition data
â”‚   â””â”€â”€ processed/     # Processed numpy arrays
â”œâ”€â”€ docs/              # Documentation
â”œâ”€â”€ logs/              # Training logs
â”œâ”€â”€ models/            # Saved models
â”‚   â”œâ”€â”€ checkpoints/   # Model checkpoints
â”‚   â””â”€â”€ final/         # Final trained models
â”œâ”€â”€ reports/           # Generated analysis reports
â”‚   â””â”€â”€ figures/       # Generated graphics
â”œâ”€â”€ scripts/           # Utility scripts
â”œâ”€â”€ src/               # Source code
â”‚   â”œâ”€â”€ data/          # Data processing modules
â”‚   â”œâ”€â”€ models/        # Model implementations
â”‚   â””â”€â”€ visualization/ # Visualization tools
â””â”€â”€ tests/             # Test files
```

## Installation

1. Clone the repository:
```bash
git clone [repository-url]
cd transformer
```

2. Create and activate a virtual environment:
```bash
python -m venv venv_directml
source venv_directml/bin/activate  # Linux/Mac
# OR
.\\venv_directml\\Scripts\\activate  # Windows
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

## Quick Start

### 1. Verify GPU Setup

```bash
python scripts/verify_gpu.py
```

### 2. Create Dataset

For quick experimentation with 1000 series:
```bash
python scripts/create_dataset.py --start-series 1 --end-series 48000 --sample-size 1000
```

For full dataset:
```bash
python scripts/create_dataset.py --start-series 1 --end-series 48000
```

### 3. Train Models

Train a point prediction model:
```bash
python scripts/train.py --start-series 1 --end-series 48000 --sample-size 1000
```

Train a probabilistic model:
```bash
python scripts/train.py --start-series 1 --end-series 48000 --sample-size 1000 --probabilistic --loss-type gaussian_nll
```

## Model Types

### Point Prediction Model

- Outputs single value predictions
- Uses MSE loss by default
- Metrics include MAE
- Best for applications requiring exact value forecasts

### Probabilistic Model

- Outputs both mean and uncertainty estimates
- Three loss function options:
  1. `gaussian_nll`: Gaussian Negative Log Likelihood
  2. `smape`: Symmetric Mean Absolute Percentage Error
  3. `hybrid`: Combination of sMAPE and Gaussian NLL
- Best for applications requiring uncertainty quantification

## Training Options

Key command-line arguments:

```bash
--start-series INT     # Starting series index
--end-series INT      # Ending series index
--sample-size INT     # Number of series to sample
--batch-size INT      # Training batch size
--epochs INT          # Number of training epochs
--sequence-length INT # Input sequence length
--probabilistic       # Enable probabilistic predictions
--loss-type STR      # Loss function type
--loss-alpha FLOAT   # Weight for hybrid loss
```

## Resource Requirements

Memory usage scales with sample size:
- 100 series: ~2GB RAM
- 1,000 series: ~8GB RAM
- 10,000 series: ~40GB RAM

Training time (approximate):
- 100 series: ~1 hour
- 1,000 series: ~10 hours
- 10,000 series: ~100 hours

## Best Practices

1. Start with small samples (100-500 series) for initial experiments
2. Use medium samples (1,000-5,000) for architecture tuning
3. Use large samples (10,000+) for final validation
4. Train on full dataset for production deployment
5. Monitor GPU memory usage during training
6. Use consistent random seeds for reproducibility

## Evaluation

Models are evaluated using:
- Validation set (20% of processed sequences)
- Multiple metrics (MAE, MSE, NLL for probabilistic models)
- Visualization of predictions and uncertainty

Run evaluation:
```bash
python scripts/test_predictions.py --start-series 1 --end-series 48000 --sample-size 1000 --n-steps 36
```

## Documentation

For detailed information about specific features:

- [Sampling Large Datasets](docs/sampling_large_datasets.md)

## Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## License

[Your License Here]

## Acknowledgments

- M4 Competition for the dataset
- Microsoft for DirectML support
